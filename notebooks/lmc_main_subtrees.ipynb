{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of src.skeleton failed: Traceback (most recent call last):\n",
      "  File \"/mnt/home/nchua/miniconda3/envs/wasp-lite/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/mnt/home/nchua/miniconda3/envs/wasp-lite/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/mnt/home/nchua/miniconda3/envs/wasp-lite/lib/python3.8/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/mnt/home/nchua/miniconda3/envs/wasp-lite/lib/python3.8/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 604, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 844, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 981, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 911, in source_to_code\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/mnt/home/nchua/src/cx-analysis/src/skeleton.py\", line 4\n",
      "    sys.path.append(expanduser('~/src/cx-analysis/src'))from src.catmaid_queries import *\n",
      "                                                        ^\n",
      "SyntaxError: invalid syntax\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of config failed: Traceback (most recent call last):\n",
      "  File \"/mnt/home/nchua/miniconda3/envs/wasp-lite/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/mnt/home/nchua/miniconda3/envs/wasp-lite/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 410, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/mnt/home/nchua/miniconda3/envs/wasp-lite/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/mnt/home/nchua/miniconda3/envs/wasp-lite/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 317, in update_class\n",
      "    update_instances(old, new)\n",
      "  File \"/mnt/home/nchua/miniconda3/envs/wasp-lite/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 280, in update_instances\n",
      "    ref.__class__ = new\n",
      "TypeError: __class__ assignment: 'Config' object layout differs from 'Config'\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os.path import exists, expanduser\n",
    "import sys\n",
    "\n",
    "from cx_analysis.skeleton_morphology import run_morphology_analysis\n",
    "#from cx_analysis.connectome import Connectome\n",
    "from cx_analysis.utils import load_preprocessed_connectome, yymmdd_today\n",
    "#from cx_analysis.node_ops import segment_skeleton, find_end_points, find_central_segment, measure_path_lengths, measure_seg_distances\n",
    "from cx_analysis.vis.fig_tools import subtype_cm\n",
    "\n",
    "plt.rcdefaults()\n",
    "#plt.style.use('cx_analysis/vis/lamina.mplstyle') # may not work if installed as a module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle loaded from: /Users/nchua/Data/210809_lamina/210809_preprocessed.pickle\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'connectome'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f540d7b11e1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'210809'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_preprocessed_connectome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"~/Data/{tp}_lamina/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/src/cx-analysis/cx_analysis/utils.py\u001b[0m in \u001b[0;36mload_preprocessed_connectome\u001b[0;34m(data_dir)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# TODO change to pkl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpack_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*_preprocessed.pickle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/cx-analysis/cx_analysis/utils.py\u001b[0m in \u001b[0;36munpack_pickle\u001b[0;34m(data_dir, f_regex)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Pickle loaded from: {path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'connectome'"
     ]
    }
   ],
   "source": [
    "tp = '210809'\n",
    "C = load_preprocessed_connectome(f\"~/Data/{tp}_lamina/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'C' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-465f27cb874e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresults_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'~/Data/{tp}_lamina/{tp}_lmc-morphology.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlmc_sts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'LMC_1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'LMC_2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'LMC_3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'LMC_4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'LMC_N'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m#, 'LMC_3', 'LMC_4']#, 'LMC_N']#, 'R7', 'R8', 'R7p']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlmc_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskel_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtype\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlmc_sts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'C' is not defined"
     ]
    }
   ],
   "source": [
    "results_file = expanduser(f'~/Data/{tp}_lamina/{tp}_lmc-morphology.json')\n",
    "lmc_sts = ['LMC_1', 'LMC_2', 'LMC_3', 'LMC_4', 'LMC_N']#, 'LMC_3', 'LMC_4']#, 'LMC_N']#, 'R7', 'R8', 'R7p']\n",
    "lmc_ids = [s for s, data in C.skel_data.items() if data.subtype in lmc_sts]\n",
    "\n",
    "if exists(results_file):\n",
    "    with open(results_file, 'r') as fh:\n",
    "        d = json.load(fh)\n",
    "        segments, central_segs, seg_lens, seg_dists, strahler = d['segments'], d['central_segs'], d['seg_lengths'], d['seg_distances'], d['strahler']\n",
    "else:\n",
    "    segments, central_segs, seg_lens, seg_dists, strahler = run_morphology_analysis(C, lmc_ids, \n",
    "                                                                                    restrict_tags='lamina_end', \n",
    "                                                                                    save_file=results_file, \n",
    "                                                                                    verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = []\n",
    "for s in lmc_ids:\n",
    "    data = C.skel_data[s]\n",
    "    \n",
    "    summary.append({'name': data.name,\n",
    "                    'skel_id': data.skel_id,\n",
    "                    'om': data.group,\n",
    "                    'subtype': data.subtype,\n",
    "                    'n_central_nodes': len(central_segs[s]), \n",
    "                    'n_nodes': len(data.skel_nodes) - len(data.r_nodes), \n",
    "                    'n_segments': len(segments[s]),\n",
    "                    'total_path_len': sum([v for k, v in seg_lens[s].items()]),\n",
    "                    'strahler_num': max([v for k, v in strahler[s].items()])})\n",
    "    \n",
    "cell_df = pd.DataFrame(summary).set_index('skel_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_data = []\n",
    "major_segs = []\n",
    "\n",
    "def div(num: float, denom: float):\n",
    "    if denom == 0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return float(num)/float(denom)\n",
    "\n",
    "for s, segmented in segments.items():\n",
    "    for seg_ind, seg in segmented.items():\n",
    "        if int(seg_ind) in central_segs[s]:  # seg_ind = seg[1]\n",
    "            #print(f\"skip {seg_ind}\")\n",
    "            continue\n",
    "        #elif (int(seg[0]) in central_segs[s]) and strahler[s][str(seg[-1])] == 1:\n",
    "        elif (int(seg[0]) in central_segs[s]) and (strahler[s][str(seg[-1])] == 1):\n",
    "            continue  # exclude knobs, maybe also try a min length?\n",
    "        else:\n",
    "            strahl_ind = seg[-1]  \n",
    "            # strahler[s] is indexed by last node of the segment  \n",
    "            this_seg = {'skel_id': str(s),\n",
    "                         'name': cell_df.loc[s, 'name'], \n",
    "                        'om': cell_df.loc[s, 'om'], \n",
    "                         'subtype': cell_df.loc[s, 'subtype'],\n",
    "                         'ind': seg_ind,\n",
    "                         'dist': seg_dists[s][seg_ind], \n",
    "                         'len': seg_lens[s][seg_ind],\n",
    "                         'tortuosity': div(seg_lens[s][seg_ind], seg_dists[s][seg_ind]), \n",
    "                         'strahl_ord': strahler[s][str(strahl_ind)]}\n",
    "            seg_data.append(this_seg)\n",
    "            if int(seg[0]) in central_segs[s]:\n",
    "                major_segs.append(this_seg)\n",
    "\n",
    "seg_df = pd.DataFrame(seg_data)\n",
    "major_df = pd.DataFrame(major_segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtree_total(current_ind, segs, seg_measurements, total=0.0):\n",
    "    \n",
    "    # branch index for the first and last node of the segment\n",
    "    \n",
    "    start = current_ind\n",
    "    end = segs[str(start)][-1]  \n",
    "    total += seg_measurements[str(start)] # get current segment's measurement\n",
    "    next_inds = [int(k) for k, v in segs.items() if (v[0] == end)]\n",
    "    if len(next_inds) == 0:\n",
    "        return total\n",
    "    else:\n",
    "        for i in next_inds:\n",
    "            total += subtree_total(i, segs, seg_measurements, total)\n",
    "        return total\n",
    "    \n",
    "\n",
    "subtree_total_len = []\n",
    "subtree_total_dist = []\n",
    "for i, seg_data in major_df.iterrows():\n",
    "    skel_id = seg_data['skel_id']\n",
    "    these_segs = segments[skel_id]\n",
    "\n",
    "    seg_ind = seg_data['ind']\n",
    "    subtree_total_len.append(subtree_total(seg_ind, these_segs, seg_lens[skel_id]))\n",
    "    subtree_total_dist.append(subtree_total(seg_ind, these_segs, seg_dists[skel_id]))\n",
    "    \n",
    "major_df['subtree_len'] = subtree_total_len\n",
    "major_df['subtree_dist'] = subtree_total_dist\n",
    "major_df['subtree_tortu'] = major_df['subtree_len'] / major_df['subtree_dist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_df['subtree_len'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, sharex=True, sharey=True, figsize=[8, 25])\n",
    "#bins = np.arange(1.0, 4.0, 0.05)\n",
    "i = 0\n",
    "\n",
    "for st, seg in major_df.groupby('subtype'):\n",
    "\n",
    "    xdata = seg['strahl_ord']\n",
    "    ydata = np.log10(seg['subtree_len'])\n",
    "        \n",
    "    #axes[i].scatter(xdata, ydata)\n",
    "    \n",
    "    sns.regplot(x=xdata, y=ydata, ax=axes[i])\n",
    "    #axes[i].set_yscale('log')\n",
    "    axes[i].set_title(f\"Length and strahler order of main subtrees: {st}\"\n",
    "                      + f\" n={len(xdata)}\")\n",
    "    axes[i].set_xlabel('Strahler order of subtree')\n",
    "    axes[i].set_ylabel('Log subtree length')\n",
    "    axes[i].set_xlim([1, 25])\n",
    "    \n",
    "    #print(np.log10(seg['subtree_len'].max()))\n",
    "    \n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_cm = subtype_cm()\n",
    "fig, ax = plt.subplots(1, figsize=[8, 8])\n",
    "#bins = np.arange(1.0, 4.0, 0.05)\n",
    "i = 0\n",
    "\n",
    "for st, seg in major_df.groupby('subtype'):\n",
    "\n",
    "    xdata = seg['strahl_ord']\n",
    "    ydata = np.log10(seg['subtree_len'])\n",
    "        \n",
    "    #axes[i].scatter(xdata, ydata)\n",
    "    #ax.set_yscale('log')\n",
    "    sns.regplot(x=xdata, y=ydata, ax=ax, color=st_cm[st])\n",
    "    i += 1\n",
    "    \n",
    "ax.set_title(f\"Length and strahler order of main subtrees\")\n",
    "ax.set_xlabel('Strahler order')\n",
    "ax.set_ylabel('Log length')\n",
    "ax.set_xlim([1, 25])\n",
    "ax.set_ylim([1, major_df['strahl_ord'].max()])\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, sharex=True, sharey=True, figsize=[8, 16])\n",
    "#bins = np.arange(1.0, 4.0, 0.05)\n",
    "i = 0\n",
    "\n",
    "for st, seg in major_df.groupby('subtype'):\n",
    "    xdata = []\n",
    "    ydata = []\n",
    "    for om, segseg in seg.groupby('om'):\n",
    "        om_total = major_df.loc[major_df['om'] == om, 'subtree_len'].sum()\n",
    "        xdata.append(segseg['strahl_ord'].mean())\n",
    "        #print(segseg['subtree_len'].mean())\n",
    "        ydata.append(segseg['subtree_len'].mean())\n",
    "    ## try w/o log\n",
    "    axes[i].set_yscale('log')    \n",
    "    axes[i].scatter(xdata, ydata, c=st_cm[st])\n",
    "    axes[i].set_xlabel('Mean Strahler order of main subtrees')\n",
    "    axes[i].set_ylabel('Mean path length')\n",
    "    \n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, sharex=True, sharey=True, figsize=[8, 16])\n",
    "#bins = np.arange(1.0, 4.0, 0.05)\n",
    "i = 0\n",
    "\n",
    "for st, seg in major_df.groupby('subtype'):\n",
    "    xdata = []\n",
    "    ydata = []\n",
    "    for om, segseg in seg.groupby('om'):\n",
    "        om_total = major_df.loc[major_df['om'] == om, 'subtree_len'].sum()\n",
    "        xdata.append(segseg['strahl_ord'].mean())\n",
    "        ydata.append(np.log10(segseg['subtree_len'].mean()/om_total))\n",
    "    axes[i].set_yscale('log')    \n",
    "    axes[i].scatter(xdata, ydata, c=st_cm[st])\n",
    "    axes[i].set_xlabel('Mean Strahler order of main subtrees')\n",
    "    axes[i].set_ylabel('Log mean path length')\n",
    "    \n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(5, sharex=True, sharey=True, figsize=[8, 16])\n",
    "#bins = np.arange(1.0, 4.0, 0.05)\n",
    "i = 0\n",
    "\n",
    "for st, seg in major_df.groupby('subtype'):\n",
    "    xdata = seg['strahl_ord']\n",
    "    ydata = seg['subtree_tortu']\n",
    "    \n",
    "    #axes[i].set_yscale('log')    \n",
    "    ax[i].scatter(xdata, ydata, c=st_cm[st])\n",
    "\n",
    "#ax.set_yscale('log')\n",
    "    ax[i].set_xlabel('Sth')\n",
    "    ax[i].set_ylabel('Tortuosity')\n",
    "    i+=1\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subtype, subtrees in major_df.groupby('subtype'):\n",
    "    \n",
    "    \n",
    "    print(subtrees['subtree_len'].mean())\n",
    "    print(subtrees['subtree_len'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wasp",
   "language": "python",
   "name": "wasp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
