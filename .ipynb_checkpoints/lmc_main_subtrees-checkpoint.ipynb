{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Connectome' from partially initialized module 'src.connectome' (most likely due to a circular import) (/mnt/home/nchua/src/cx-analysis/src/connectome.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ff9ef1554a9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanduser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskeleton_morphology\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrun_morphology_analysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m#from src.connectome import Connectome\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_preprocessed_connectome\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myymmdd_today\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/cx-analysis/src/skeleton_morphology.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msegment_skeleton\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfind_central_segment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeasure_path_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeasure_seg_distances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnectome\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConnectome\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatmaid_queries\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_root_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \"\"\"\n",
      "\u001b[0;32m~/src/cx-analysis/src/connectome.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskeleton\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSkeleton\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatmaid_queries\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/cx-analysis/src/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnectome\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConnectome\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskeleton\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSkeleton\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Connectome' from partially initialized module 'src.connectome' (most likely due to a circular import) (/mnt/home/nchua/src/cx-analysis/src/connectome.py)"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os.path import exists, expanduser\n",
    "\n",
    "from src.skeleton_morphology import run_morphology_analysis\n",
    "#from src.connectome import Connectome\n",
    "from src.utils import load_preprocessed_connectome, yymmdd_today\n",
    "#from src.node_ops import segment_skeleton, find_end_points, find_central_segment, measure_path_lengths, measure_seg_distances\n",
    "from vis.fig_tools import subtype_cm\n",
    "\n",
    "plt.rcdefaults()\n",
    "plt.style.use('vis/lamina.mplstyle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = '210507'\n",
    "C = load_preprocessed_connectome(f\"~/Data/{tp}_lamina/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_file = expanduser(f'~/Data/{tp}_lamina/210419_lmc-morphology.json')\n",
    "lmc_sts = ['LMC_1', 'LMC_2', 'LMC_3', 'LMC_4', 'LMC_N']#, 'LMC_3', 'LMC_4']#, 'LMC_N']#, 'R7', 'R8', 'R7p']\n",
    "lmc_ids = [s for s, data in C.skel_data.items() if data.subtype in lmc_sts]\n",
    "\n",
    "if exists(results_file):\n",
    "    with open(results_file, 'r') as fh:\n",
    "        d = json.load(fh)\n",
    "        segments, central_segs, seg_lens, seg_dists, strahler = d['segments'], d['central_segs'], d['seg_lengths'], d['seg_distances'], d['strahler']\n",
    "else:\n",
    "    segments, central_segs, seg_lens, seg_dists, strahler = run_morphology_analysis(C, lmc_ids, \n",
    "                                                                                    restrict_tags='lamina_end', \n",
    "                                                                                    save_file=results_file, \n",
    "                                                                                    verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = []\n",
    "for s in lmc_ids:\n",
    "    data = C.skel_data[s]\n",
    "    \n",
    "    summary.append({'name': data.name,\n",
    "                    'skel_id': data.skel_id,\n",
    "                    'om': data.group,\n",
    "                    'subtype': data.subtype,\n",
    "                    'n_central_nodes': len(central_segs[s]), \n",
    "                    'n_nodes': len(data.skel_nodes) - len(data.r_nodes), \n",
    "                    'n_segments': len(segments[s]),\n",
    "                    'total_path_len': sum([v for k, v in seg_lens[s].items()]),\n",
    "                    'strahler_num': max([v for k, v in strahler[s].items()])})\n",
    "    \n",
    "cell_df = pd.DataFrame(summary).set_index('skel_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_data = []\n",
    "major_segs = []\n",
    "\n",
    "def div(num: float, denom: float):\n",
    "    if denom == 0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return float(num)/float(denom)\n",
    "\n",
    "for s, segmented in segments.items():\n",
    "    for seg_ind, seg in segmented.items():\n",
    "        if int(seg_ind) in central_segs[s]:  # seg_ind = seg[1]\n",
    "            #print(f\"skip {seg_ind}\")\n",
    "            continue\n",
    "        #elif (int(seg[0]) in central_segs[s]) and strahler[s][str(seg[-1])] == 1:\n",
    "        elif (int(seg[0]) in central_segs[s]) and (strahler[s][str(seg[-1])] == 1):\n",
    "            continue  # exclude knobs, maybe also try a min length?\n",
    "        else:\n",
    "            strahl_ind = seg[-1]  \n",
    "            # strahler[s] is indexed by last node of the segment  \n",
    "            this_seg = {'skel_id': str(s),\n",
    "                         'name': cell_df.loc[s, 'name'], \n",
    "                        'om': cell_df.loc[s, 'om'], \n",
    "                         'subtype': cell_df.loc[s, 'subtype'],\n",
    "                         'ind': seg_ind,\n",
    "                         'dist': seg_dists[s][seg_ind], \n",
    "                         'len': seg_lens[s][seg_ind],\n",
    "                         'tortuosity': div(seg_lens[s][seg_ind], seg_dists[s][seg_ind]), \n",
    "                         'strahl_ord': strahler[s][str(strahl_ind)]}\n",
    "            seg_data.append(this_seg)\n",
    "            if int(seg[0]) in central_segs[s]:\n",
    "                major_segs.append(this_seg)\n",
    "\n",
    "seg_df = pd.DataFrame(seg_data)\n",
    "major_df = pd.DataFrame(major_segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtree_total(current_ind, segs, seg_measurements, total=0.0):\n",
    "    \n",
    "    # branch index for the first and last node of the segment\n",
    "    \n",
    "    start = current_ind\n",
    "    end = segs[str(start)][-1]  \n",
    "    total += seg_measurements[str(start)] # get current segment's measurement\n",
    "    next_inds = [int(k) for k, v in segs.items() if (v[0] == end)]\n",
    "    if len(next_inds) == 0:\n",
    "        return total\n",
    "    else:\n",
    "        for i in next_inds:\n",
    "            total += subtree_total(i, segs, seg_measurements, total)\n",
    "        return total\n",
    "    \n",
    "\n",
    "subtree_total_len = []\n",
    "subtree_total_dist = []\n",
    "for i, seg_data in major_df.iterrows():\n",
    "    skel_id = seg_data['skel_id']\n",
    "    these_segs = segments[skel_id]\n",
    "\n",
    "    seg_ind = seg_data['ind']\n",
    "    subtree_total_len.append(subtree_total(seg_ind, these_segs, seg_lens[skel_id]))\n",
    "    subtree_total_dist.append(subtree_total(seg_ind, these_segs, seg_dists[skel_id]))\n",
    "    \n",
    "major_df['subtree_len'] = subtree_total_len\n",
    "major_df['subtree_dist'] = subtree_total_dist\n",
    "major_df['subtree_tortu'] = major_df['subtree_len'] / major_df['subtree_dist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_df['subtree_len'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, sharex=True, sharey=True, figsize=[8, 25])\n",
    "#bins = np.arange(1.0, 4.0, 0.05)\n",
    "i = 0\n",
    "\n",
    "for st, seg in major_df.groupby('subtype'):\n",
    "\n",
    "    xdata = seg['strahl_ord']\n",
    "    ydata = np.log10(seg['subtree_len'])\n",
    "        \n",
    "    #axes[i].scatter(xdata, ydata)\n",
    "    \n",
    "    sns.regplot(x=xdata, y=ydata, ax=axes[i])\n",
    "    #axes[i].set_yscale('log')\n",
    "    axes[i].set_title(f\"Length and strahler order of main subtrees: {st}\"\n",
    "                      + f\" n={len(xdata)}\")\n",
    "    axes[i].set_xlabel('Strahler order of subtree')\n",
    "    axes[i].set_ylabel('Log subtree length')\n",
    "    axes[i].set_xlim([1, 25])\n",
    "    \n",
    "    #print(np.log10(seg['subtree_len'].max()))\n",
    "    \n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_cm = subtype_cm()\n",
    "fig, ax = plt.subplots(1, figsize=[8, 8])\n",
    "#bins = np.arange(1.0, 4.0, 0.05)\n",
    "i = 0\n",
    "\n",
    "for st, seg in major_df.groupby('subtype'):\n",
    "\n",
    "    xdata = seg['strahl_ord']\n",
    "    ydata = np.log10(seg['subtree_len'])\n",
    "        \n",
    "    #axes[i].scatter(xdata, ydata)\n",
    "    #ax.set_yscale('log')\n",
    "    sns.regplot(x=xdata, y=ydata, ax=ax, color=st_cm[st])\n",
    "    i += 1\n",
    "    \n",
    "ax.set_title(f\"Length and strahler order of main subtrees\")\n",
    "ax.set_xlabel('Strahler order')\n",
    "ax.set_ylabel('Log length')\n",
    "ax.set_xlim([1, 25])\n",
    "ax.set_ylim([1, major_df['strahl_ord'].max()])\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, sharex=True, sharey=True, figsize=[8, 16])\n",
    "#bins = np.arange(1.0, 4.0, 0.05)\n",
    "i = 0\n",
    "\n",
    "for st, seg in major_df.groupby('subtype'):\n",
    "    xdata = []\n",
    "    ydata = []\n",
    "    for om, segseg in seg.groupby('om'):\n",
    "        om_total = major_df.loc[major_df['om'] == om, 'subtree_len'].sum()\n",
    "        xdata.append(segseg['strahl_ord'].mean())\n",
    "        #print(segseg['subtree_len'].mean())\n",
    "        ydata.append(segseg['subtree_len'].mean())\n",
    "    ## try w/o log\n",
    "    axes[i].set_yscale('log')    \n",
    "    axes[i].scatter(xdata, ydata, c=st_cm[st])\n",
    "    axes[i].set_xlabel('Mean Strahler order of main subtrees')\n",
    "    axes[i].set_ylabel('Mean path length')\n",
    "    \n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, sharex=True, sharey=True, figsize=[8, 16])\n",
    "#bins = np.arange(1.0, 4.0, 0.05)\n",
    "i = 0\n",
    "\n",
    "for st, seg in major_df.groupby('subtype'):\n",
    "    xdata = []\n",
    "    ydata = []\n",
    "    for om, segseg in seg.groupby('om'):\n",
    "        om_total = major_df.loc[major_df['om'] == om, 'subtree_len'].sum()\n",
    "        xdata.append(segseg['strahl_ord'].mean())\n",
    "        ydata.append(np.log10(segseg['subtree_len'].mean()/om_total))\n",
    "    axes[i].set_yscale('log')    \n",
    "    axes[i].scatter(xdata, ydata, c=st_cm[st])\n",
    "    axes[i].set_xlabel('Mean Strahler order of main subtrees')\n",
    "    axes[i].set_ylabel('Log mean path length')\n",
    "    \n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(5, sharex=True, sharey=True, figsize=[8, 16])\n",
    "#bins = np.arange(1.0, 4.0, 0.05)\n",
    "i = 0\n",
    "\n",
    "for st, seg in major_df.groupby('subtype'):\n",
    "    xdata = seg['strahl_ord']\n",
    "    ydata = seg['subtree_tortu']\n",
    "    \n",
    "    #axes[i].set_yscale('log')    \n",
    "    ax[i].scatter(xdata, ydata, c=st_cm[st])\n",
    "\n",
    "#ax.set_yscale('log')\n",
    "    ax[i].set_xlabel('Sth')\n",
    "    ax[i].set_ylabel('Tortuosity')\n",
    "    i+=1\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subtype, subtrees in major_df.groupby('subtype'):\n",
    "    \n",
    "    \n",
    "    print(subtrees['subtree_len'].mean())\n",
    "    print(subtrees['subtree_len'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wasp-lite",
   "language": "python",
   "name": "wasp-lite"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
